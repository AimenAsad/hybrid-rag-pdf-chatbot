# Chat with PDF (Hybrid RAG using LangChain, Ollama & FAISS)

A local **"Chat with PDF"** application that lets you query multiple PDFs using **Hybrid Retrieval-Augmented Generation (RAG)** combining **semantic search** (FAISS vector embeddings) with **keyword search** for better accuracy.  

No paid APIs needed â€” runs entirely **offline** with [Ollama](https://ollama.ai) and your own PDFs.

---

## Features
**Multiple PDF Support** â€“ Load any number of PDFs from a folder  
**Hybrid Retrieval** â€“ Combines semantic search with keyword matching  
**Local LLM & Embeddings** â€“ Uses Ollama (`llama3:instruct` + `nomic-embed-text`)  
**Source Metadata** â€“ Retrieves context with PDF file name & page number  
**Web UI** â€“ Built with Gradio for easy interaction  
**Runs 100% Locally** â€“ No internet or paid APIs required  

---

## ğŸ–¼ Tech Architecture
PDFs â†’ Loader (PyMuPDF) â†’ Text Chunking â†’ Embeddings (Ollama) â†’ FAISS Vector Store â†” Hybrid Retriever â†” LLM (Ollama) â†’ Answer

---

## Project Structure

RAG/
â”‚â”€â”€ app.py # Gradio Web App<br>
â”‚â”€â”€ main.py # CLI test script<br>
â”‚â”€â”€ vector_embedding.py # Vector store builder<br>
â”‚â”€â”€ hybrid_retriever.py # Hybrid (semantic + keyword) search<br>
â”‚â”€â”€ retriever.py # FAISS-only retriever<br>
â”‚â”€â”€ pdf_loader.py # Loads PDFs from folder<br>
â”‚â”€â”€ chunking.py # Splits text into chunks<br>
â”‚â”€â”€ RAG-dataset/ # Your PDFs<br>
â”‚â”€â”€ faiss_index/ # Saved FAISS index<br>
â”‚â”€â”€ requirements.txt<br>
â”‚â”€â”€ README.md


---

## Installation & Setup
### 1ï¸ Clone Repository

git clone <https://github.com/AimenAsad/hybrid-rag-pdf-chatbot.git>

### 2ï¸ Create Virtual Environment

python3 -m venv rag_env
source rag_env/bin/activate

### 3ï¸ Install Dependencies

pip install -r requirements.txt

### 4ï¸ Install & Pull Ollama Models

ollama pull llama3:instruct
ollama pull nomic-embed-text

### 5ï¸ Add PDFs

Place your PDFs in the RAG-dataset/ folder.

### 6ï¸ Build Vector Store

python3 vector_embedding.py

### 7ï¸ Run Web App

python3 app.py

---

## Example Questions

Top three most consumed supplements<br>
What are side effects of creatine?<br>
How to gain muscle mass effectively?<br>
Which supplements help with fat loss?

## How It Works

PDF Loader â€“ Loads PDFs and extracts text using PyMuPDF<br>
Chunking â€“ Splits long text into smaller chunks for better retrieval<br>
Embedding â€“ Converts chunks into vectors using nomic-embed-text model<br>
FAISS Vector Store â€“ Stores embeddings for fast similarity search<br>
Hybrid Retrieval â€“ Combines:<br>
Semantic Search â†’ Finds context by meaning<br>
Keyword Search â†’ Matches exact terms from query<br>
LLM Response â€“ Sends retrieved chunks to llama3:instruct for answer generation

## Why Hybrid Retrieval?

Semantic Search sometimes misses obvious keyword matches<br>
Keyword Search can't handle synonyms or rephrasing<br>
Hybrid ensures higher recall + better accuracy
